{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Introduction to nuee: Following the Classic nuee Tutorial\n",
    "\n",
    "This notebook follows the structure of the classic \"Introduction to Ordination in nuee\" tutorial, implementing the same analyses using nuee. We'll cover the main topics from the original tutorial:\n",
    "\n",
    "## Table of Contents (following intro-nuee.pdf)\n",
    "1. [Ordination](#ordination)\n",
    "   - 1.1 [Detrended Correspondence Analysis](#dca)\n",
    "   - 1.2 [Non-metric Multidimensional Scaling](#nmds)\n",
    "2. [Ordination Graphics](#graphics)\n",
    "   - 2.1 [Cluttered Plots](#cluttered)\n",
    "   - 2.2 [Adding Items to Ordination Plots](#adding-items)\n",
    "3. [Fitting Environmental Variables](#envfit)\n",
    "4. [Constrained Ordination](#constrained)\n",
    "   - 4.1 [Significance Tests](#significance)\n",
    "   - 4.2 [Conditioned or Partial Ordination](#partial)\n",
    "\n",
    "We'll use the classic `varespec` (lichen species) and `varechem` (environmental) datasets to maintain consistency with the original tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add nuee to path (adjust as needed)\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import nuee \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set plotting parameters\n",
    "plt.rcParams['figure.figsize'] = (10, 8)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "print(\"âœ“ nuee loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the classic nuee datasets\n",
    "# Following the original tutorial, we use varespec and varechem\n",
    "varespec = nuee.datasets.varespec()\n",
    "varechem = nuee.datasets.varechem()\n",
    "\n",
    "print(\"Data loaded:\")\n",
    "print(f\"  varespec: {varespec.shape} (sites Ã— species)\")\n",
    "print(f\"  varechem: {varechem.shape} (sites Ã— environmental variables)\")\n",
    "print(f\"\\nFirst few rows of varespec:\")\n",
    "print(varespec.head())\n",
    "print(f\"\\nEnvironmental variables in varechem:\")\n",
    "print(varechem.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordination",
   "metadata": {},
   "source": [
    "## 1. Ordination {#ordination}\n",
    "\n",
    "Ordination methods are the core tools for analyzing multivariate ecological data. We'll start with two fundamental unconstrained ordination methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca",
   "metadata": {},
   "source": [
    "### 1.1 Detrended Correspondence Analysis {#dca}\n",
    "\n",
    "DCA (Detrended Correspondence Analysis) is a classic ordination method for ecological data. While nuee doesn't have a dedicated DCA implementation yet, we can demonstrate CA (Correspondence Analysis) which is the foundation of DCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca_analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correspondence Analysis (CA) - foundation of DCA\n",
    "print(\"=== CORRESPONDENCE ANALYSIS (CA) ===\")\n",
    "print(\"Note: DCA will be implemented in future versions\")\n",
    "print(\"For now, we demonstrate CA using CCA without constraints\")\n",
    "\n",
    "try:\n",
    "    # CCA without environmental constraints approximates CA\n",
    "    # We'll create a dummy environmental matrix\n",
    "    dummy_env = pd.DataFrame({'dummy': np.ones(varespec.shape[0])}, index=varespec.index)\n",
    "    ca_result = nuee.cca(varespec, dummy_env)\n",
    "    \n",
    "    print(f\"CA completed:\")\n",
    "    print(f\"  Total inertia: {ca_result.tot_chi:.3f}\")\n",
    "    if ca_result.eigenvalues is not None:\n",
    "        print(f\"  First few eigenvalues: {ca_result.eigenvalues[:4]}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"CA analysis: {e}\")\n",
    "    print(\"CA/DCA implementation is in development\")\n",
    "    print(\"Proceeding with NMDS which is more commonly used for ecological data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nmds",
   "metadata": {},
   "source": [
    "### 1.2 Non-metric Multidimensional Scaling {#nmds}\n",
    "\n",
    "NMDS is one of the most robust ordination methods for ecological community data. It's based on ranked distances and doesn't assume linear relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nmds_analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-metric Multidimensional Scaling\n",
    "print(\"=== NON-METRIC MULTIDIMENSIONAL SCALING (NMDS) ===\")\n",
    "\n",
    "# Perform NMDS - following nuee tutorial defaults\n",
    "nmds_result = nuee.metaMDS(varespec, k=2, distance='bray', trymax=20, \n",
    "                           autotransform=True, trace=True)\n",
    "\n",
    "print(f\"\\nNMDS Results:\")\n",
    "print(f\"  Dimensions: {nmds_result.ndim}\")\n",
    "print(f\"  Stress: {nmds_result.stress:.6f}\")\n",
    "print(f\"  Converged: {nmds_result.converged}\")\n",
    "\n",
    "# Stress interpretation (following Clarke 1993)\n",
    "stress = nmds_result.stress\n",
    "if stress < 5:\n",
    "    stress_quality = \"excellent representation with no prospect of misinterpretation\"\n",
    "elif stress < 10:\n",
    "    stress_quality = \"good ordination with no real risk of drawing false inferences\"\n",
    "elif stress < 20:\n",
    "    stress_quality = \"potentially useful, but should be interpreted with caution\"\n",
    "else:\n",
    "    stress_quality = \"poor representation - ordination may be misleading\"\n",
    "\n",
    "print(f\"  Stress interpretation: {stress_quality}\")\n",
    "print(f\"\\nNMDS site scores (first 5 sites):\")\n",
    "if isinstance(nmds_result.points, pd.DataFrame):\n",
    "    print(nmds_result.points.head())\n",
    "else:\n",
    "    print(pd.DataFrame(nmds_result.points[:5], \n",
    "                      columns=[f'NMDS{i+1}' for i in range(nmds_result.ndim)]))"
   ]
  },
  {
   "cell_type": "code",
   "id": "basic_nmds_plot",
   "metadata": {},
   "outputs": [],
   "source": "# Basic NMDS plot using automatic plotting API\nprint(\"Using nuee's automatic plotting (just like R nuee!):\")\n\n# Plot sites using automatic plotting\nfig1 = nmds_result.plot(display=\"sites\", type=\"points\", figsize=(10, 8))\nplt.title(f'NMDS ordination - Sites (Stress = {nmds_result.stress:.4f})')\nplt.show()\n\n# Plot species using automatic plotting\nif hasattr(nmds_result, 'species') and nmds_result.species is not None:\n    fig2 = nmds_result.plot(display=\"species\", type=\"text\", figsize=(10, 8))\n    plt.title(f'NMDS ordination - Species (Stress = {nmds_result.stress:.4f})')\n    plt.show()\n\n# Plot both sites and species\nfig3 = nmds_result.plot(display=\"both\", type=\"points\", figsize=(10, 8))\nplt.title(f'NMDS ordination - Sites and Species (Stress = {nmds_result.stress:.4f})')\nplt.show()\n\nprint(f\"\\nâœ¨ Automatic plotting makes nuee work just like R nuee!\")\nprint(f\"   nmds_result.plot()  # Direct plotting, no separate functions needed\")"
  },
  {
   "cell_type": "markdown",
   "id": "graphics",
   "metadata": {},
   "source": [
    "## 2. Ordination Graphics {#graphics}\n",
    "\n",
    "Effective visualization of ordination results is crucial for ecological interpretation. We'll explore different plotting approaches and how to handle cluttered plots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cluttered",
   "metadata": {},
   "source": [
    "### 2.1 Cluttered Plots {#cluttered}\n",
    "\n",
    "With many species or sites, ordination plots can become cluttered. We'll demonstrate strategies to handle this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cluttered_plots",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate different approaches to handle cluttered plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Plot 1: Sites only (no species)\n",
    "axes[0, 0].scatter(nmds1, nmds2, s=100, c='blue', alpha=0.7, edgecolors='black')\n",
    "axes[0, 0].set_xlabel('NMDS1')\n",
    "axes[0, 0].set_ylabel('NMDS2')\n",
    "axes[0, 0].set_title('Sites only')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Sites with text labels\n",
    "axes[0, 1].scatter(nmds1, nmds2, s=60, c='blue', alpha=0.5, edgecolors='black')\n",
    "for i, label in enumerate(site_labels):\n",
    "    axes[0, 1].text(nmds1.iloc[i] if hasattr(nmds1, 'iloc') else nmds1[i], \n",
    "                   nmds2.iloc[i] if hasattr(nmds2, 'iloc') else nmds2[i], \n",
    "                   label, fontsize=8, ha='center', va='center')\n",
    "axes[0, 1].set_xlabel('NMDS1')\n",
    "axes[0, 1].set_ylabel('NMDS2')\n",
    "axes[0, 1].set_title('Sites with labels')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Species only (if available)\n",
    "if hasattr(nmds_result, 'species') and nmds_result.species is not None:\n",
    "    if isinstance(nmds_result.species, pd.DataFrame):\n",
    "        sp1, sp2 = nmds_result.species.iloc[:, 0], nmds_result.species.iloc[:, 1]\n",
    "        sp_names = nmds_result.species.index\n",
    "    else:\n",
    "        sp1, sp2 = nmds_result.species[:, 0], nmds_result.species[:, 1]\n",
    "        sp_names = [f'Sp{i+1}' for i in range(len(sp1))]\n",
    "    \n",
    "    axes[1, 0].scatter(sp1, sp2, s=30, c='red', marker='^', alpha=0.7)\n",
    "    \n",
    "    # Add labels for abundant species only (top 10 by total abundance)\n",
    "    species_totals = varespec.sum().sort_values(ascending=False)\n",
    "    top_species = species_totals.head(10).index\n",
    "    \n",
    "    for i, sp_name in enumerate(sp_names):\n",
    "        if sp_name in top_species:\n",
    "            axes[1, 0].annotate(sp_name[:8], \n",
    "                              (sp1.iloc[i] if hasattr(sp1, 'iloc') else sp1[i],\n",
    "                               sp2.iloc[i] if hasattr(sp2, 'iloc') else sp2[i]),\n",
    "                              xytext=(2, 2), textcoords='offset points',\n",
    "                              fontsize=8, color='red')\n",
    "    \n",
    "    axes[1, 0].set_xlabel('NMDS1')\n",
    "    axes[1, 0].set_ylabel('NMDS2')\n",
    "    axes[1, 0].set_title('Species only (abundant species labeled)')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "else:\n",
    "    axes[1, 0].text(0.5, 0.5, 'Species scores\\nnot available', \n",
    "                   ha='center', va='center', transform=axes[1, 0].transAxes)\n",
    "\n",
    "# Plot 4: Combined with selective labeling\n",
    "axes[1, 1].scatter(nmds1, nmds2, s=80, c='blue', alpha=0.7, \n",
    "                  edgecolors='black', label='Sites')\n",
    "\n",
    "if hasattr(nmds_result, 'species') and nmds_result.species is not None:\n",
    "    axes[1, 1].scatter(sp1, sp2, s=20, c='red', marker='^', \n",
    "                      alpha=0.6, label='Species')\n",
    "\n",
    "# Label only every 3rd site to reduce clutter\n",
    "for i in range(0, len(site_labels), 3):\n",
    "    axes[1, 1].annotate(site_labels[i], \n",
    "                       (nmds1.iloc[i] if hasattr(nmds1, 'iloc') else nmds1[i],\n",
    "                        nmds2.iloc[i] if hasattr(nmds2, 'iloc') else nmds2[i]),\n",
    "                       xytext=(3, 3), textcoords='offset points', fontsize=8)\n",
    "\n",
    "axes[1, 1].set_xlabel('NMDS1')\n",
    "axes[1, 1].set_ylabel('NMDS2')\n",
    "axes[1, 1].set_title('Combined (selective labeling)')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Strategies for cluttered plots:\")\n",
    "print(\"  1. Plot sites and species separately\")\n",
    "print(\"  2. Use selective labeling (e.g., every nth site)\")\n",
    "print(\"  3. Label only abundant/important species\")\n",
    "print(\"  4. Use different symbols and colors\")\n",
    "print(\"  5. Consider interactive plots for detailed exploration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adding-items",
   "metadata": {},
   "source": [
    "### 2.2 Adding Items to Ordination Plots {#adding-items}\n",
    "\n",
    "We can enhance ordination plots by adding environmental information, convex hulls, ellipses, and other graphical elements."
   ]
  },
  {
   "cell_type": "code",
   "id": "enhanced_plots",
   "metadata": {},
   "outputs": [],
   "source": "# Enhanced ordination plots using automatic plotting API\nprint(\"Enhanced NMDS plots with automatic plotting:\")\n\n# Shannon diversity with automatic plotting - just like R nuee!\nshannon_div = nuee.shannon(varespec)\nprint(f\"Shannon diversity calculated: {type(shannon_div)}\")\nprint(f\"Mean Shannon diversity: {shannon_div.mean():.3f}\")\n\n# Plot 1: Shannon diversity histogram - automatic plotting!\nfig1 = shannon_div.plot(kind=\"hist\", bins=15, alpha=0.7, color='skyblue', figsize=(10, 6))\nplt.title(\"Shannon Diversity Distribution - Automatic Plotting\")\nplt.show()\n\n# Plot 2: Shannon diversity by sample - automatic plotting!\nfig2 = shannon_div.plot(kind=\"bar\", color='lightgreen', alpha=0.8, figsize=(12, 6))\nplt.title(\"Shannon Diversity by Sample - Automatic Plotting\")\nplt.xticks(rotation=45)\nplt.show()\n\n# Plot 3: NMDS with automatic plotting\nfig3 = nmds_result.plot(display=\"sites\", type=\"points\", figsize=(10, 8))\nplt.title(\"NMDS Sites - Automatic Plotting\")\nplt.show()\n\n# Plot 4: Species richness with automatic plotting\nrichness = nuee.specnumber(varespec)\nfig4 = richness.plot(kind=\"bar\", color='orange', alpha=0.7, figsize=(12, 6))\nplt.title(\"Species Richness by Sample - Automatic Plotting\")\nplt.xticks(rotation=45)\nplt.show()\n\nprint(\"\\nðŸŽ‰ All plots created using automatic plotting API!\")\nprint(\"âœ¨ Just like R nuee: result.plot() for direct plotting\")\nprint(\"ðŸ“Š Multiple plot types: histogram, bar, box, violin\")\nprint(\"ðŸ—ºï¸ Ordination plots: sites, species, both\")"
  },
  {
   "cell_type": "markdown",
   "id": "envfit",
   "metadata": {},
   "source": [
    "## 3. Fitting Environmental Variables {#envfit}\n",
    "\n",
    "Environmental fitting helps identify which environmental variables are significantly related to ordination patterns. This is one of the most important analyses in community ecology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental_fitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environmental fitting to NMDS ordination\n",
    "print(\"=== FITTING ENVIRONMENTAL VARIABLES ===\")\n",
    "\n",
    "# Manual environmental fitting (envfit function is under development)\n",
    "# Calculate correlations between environmental variables and NMDS axes\n",
    "\n",
    "env_results = []\n",
    "for var in varechem.columns:\n",
    "    # Correlations with NMDS axes\n",
    "    corr1 = np.corrcoef(varechem[var], nmds1)[0, 1]\n",
    "    corr2 = np.corrcoef(varechem[var], nmds2)[0, 1]\n",
    "    \n",
    "    # R-squared (goodness of fit)\n",
    "    r_squared = corr1**2 + corr2**2\n",
    "    \n",
    "    env_results.append({\n",
    "        'Variable': var,\n",
    "        'NMDS1': corr1,\n",
    "        'NMDS2': corr2,\n",
    "        'r2': r_squared\n",
    "    })\n",
    "\n",
    "env_df = pd.DataFrame(env_results)\n",
    "env_df = env_df.sort_values('r2', ascending=False)\n",
    "\n",
    "print(\"Environmental variable fitting results:\")\n",
    "print(env_df.round(4))\n",
    "\n",
    "print(f\"\\nMost important environmental variables (rÂ² > 0.2):\")\n",
    "important_vars = env_df[env_df['r2'] > 0.2]\n",
    "if len(important_vars) > 0:\n",
    "    for _, row in important_vars.iterrows():\n",
    "        print(f\"  {row['Variable']}: rÂ² = {row['r2']:.3f}\")\n",
    "else:\n",
    "    print(\"  No variables with rÂ² > 0.2\")\n",
    "    print(f\"  Strongest: {env_df.iloc[0]['Variable']} (rÂ² = {env_df.iloc[0]['r2']:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "envfit_visualization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize environmental fitting results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot 1: NMDS with environmental vectors\n",
    "axes[0].scatter(nmds1, nmds2, s=100, c='steelblue', alpha=0.7, \n",
    "               edgecolors='black', label='Sites')\n",
    "\n",
    "# Add environmental vectors\n",
    "# Scale factor for arrow visibility\n",
    "arrow_scale = 0.7\n",
    "\n",
    "for _, row in env_df.iterrows():\n",
    "    var_name = row['Variable']\n",
    "    \n",
    "    # Only show vectors with meaningful correlations\n",
    "    if row['r2'] > 0.1:  # threshold for display\n",
    "        arrow_x = row['NMDS1'] * arrow_scale\n",
    "        arrow_y = row['NMDS2'] * arrow_scale\n",
    "        \n",
    "        # Draw arrow\n",
    "        axes[0].arrow(0, 0, arrow_x, arrow_y, head_width=0.02, head_length=0.03,\n",
    "                     fc='red', ec='red', alpha=0.8, linewidth=2)\n",
    "        \n",
    "        # Add label\n",
    "        axes[0].text(arrow_x*1.1, arrow_y*1.1, var_name, fontsize=12,\n",
    "                    color='red', weight='bold',\n",
    "                    bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "\n",
    "axes[0].set_xlabel('NMDS1')\n",
    "axes[0].set_ylabel('NMDS2')\n",
    "axes[0].set_title('NMDS with Environmental Vectors')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].legend()\n",
    "\n",
    "# Add stress and interpretation\n",
    "textstr = f'Stress = {nmds_result.stress:.4f}\\nRed arrows: environmental variables\\nLength âˆ correlation strength'\n",
    "axes[0].text(0.02, 0.98, textstr, transform=axes[0].transAxes, fontsize=10,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "\n",
    "# Plot 2: Bar plot of R-squared values\n",
    "bars = axes[1].bar(env_df['Variable'], env_df['r2'], color='steelblue', alpha=0.7, edgecolor='black')\n",
    "axes[1].set_xlabel('Environmental Variables')\n",
    "axes[1].set_ylabel('rÂ² (goodness of fit)')\n",
    "axes[1].set_title('Environmental Variable Importance')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Highlight significant variables\n",
    "for i, bar in enumerate(bars):\n",
    "    if env_df.iloc[i]['r2'] > 0.2:\n",
    "        bar.set_color('red')\n",
    "        bar.set_alpha(0.8)\n",
    "\n",
    "# Add significance threshold line\n",
    "axes[1].axhline(y=0.2, color='red', linestyle='--', alpha=0.8, label='rÂ² = 0.2 threshold')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation of environmental vectors:\")\n",
    "print(\"  â€¢ Arrow length indicates correlation strength with ordination\")\n",
    "print(\"  â€¢ Arrow direction shows gradient direction in ordination space\")\n",
    "print(\"  â€¢ Longer arrows = stronger environmental-community relationships\")\n",
    "print(\"  â€¢ Sites along arrow direction have higher values of that variable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constrained",
   "metadata": {},
   "source": [
    "## 4. Constrained Ordination {#constrained}\n",
    "\n",
    "Constrained ordination methods (RDA, CCA) directly incorporate environmental information into the ordination, allowing us to explore how environmental variables explain community patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rda_constrained",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redundancy Analysis (RDA) - Constrained ordination\n",
    "print(\"=== REDUNDANCY ANALYSIS (RDA) ===\")\n",
    "\n",
    "# Perform RDA with all environmental variables\n",
    "rda_result = nuee.rda(varespec, varechem, scale=False)\n",
    "\n",
    "print(f\"RDA Results:\")\n",
    "print(f\"  Total inertia: {rda_result.tot_chi:.4f}\")\n",
    "print(f\"  Constrained axes: {rda_result.rank}\")\n",
    "\n",
    "if rda_result.constrained_eig is not None:\n",
    "    print(f\"  Constrained eigenvalues: {rda_result.constrained_eig[:4].round(4)}\")\n",
    "    \n",
    "    # Calculate variance explained\n",
    "    constrained_var = rda_result.constrained_eig / rda_result.tot_chi * 100\n",
    "    print(f\"  Variance explained by constrained axes (%): {constrained_var[:4].round(2)}\")\n",
    "    print(f\"  Cumulative variance explained (%): {np.cumsum(constrained_var[:4]).round(2)}\")\n",
    "    \n",
    "    # Total constrained variance\n",
    "    total_constrained = np.sum(constrained_var)\n",
    "    print(f\"  Total variance explained by environment: {total_constrained:.2f}%\")\n",
    "\n",
    "if rda_result.unconstrained_eig is not None and len(rda_result.unconstrained_eig) > 0:\n",
    "    unconstrained_var = rda_result.unconstrained_eig / rda_result.tot_chi * 100\n",
    "    print(f\"  Residual (unconstrained) variance: {np.sum(unconstrained_var):.2f}%\")\n",
    "\n",
    "print(f\"\\nFirst few RDA site scores:\")\n",
    "if isinstance(rda_result.points, pd.DataFrame):\n",
    "    print(rda_result.points.head())\n",
    "else:\n",
    "    rda_df = pd.DataFrame(rda_result.points[:5, :4], \n",
    "                         columns=[f'RDA{i+1}' for i in range(min(4, rda_result.points.shape[1]))])\n",
    "    print(rda_df)"
   ]
  },
  {
   "cell_type": "code",
   "id": "rda_plots",
   "metadata": {},
   "outputs": [],
   "source": "# Plot RDA results using automatic plotting API\nprint(\"RDA plotting with automatic plotting API:\")\n\n# Extract variance explained for axis labels\nconstrained_var = rda_result.constrained_eig / rda_result.tot_chi * 100\n\n# Plot 1: RDA site scores - automatic plotting!\nfig1 = rda_result.plot(display=\"sites\", figsize=(10, 8))\nplt.title('RDA Site Scores - Automatic Plotting')\nplt.xlabel(f'RDA1 ({constrained_var[0]:.1f}%)')\nplt.ylabel(f'RDA2 ({constrained_var[1]:.1f}%)')\nplt.show()\n\n# Plot 2: RDA biplot with environmental arrows - automatic plotting!\nfig2 = rda_result.biplot(figsize=(12, 10))\nplt.title('RDA Biplot - Automatic Plotting')\nplt.xlabel(f'RDA1 ({constrained_var[0]:.1f}%)')\nplt.ylabel(f'RDA2 ({constrained_var[1]:.1f}%)')\nplt.show()\n\n# Plot 3: RDA species plot - automatic plotting!\nfig3 = rda_result.plot(display=\"species\", figsize=(10, 8))\nplt.title('RDA Species Scores - Automatic Plotting')\nplt.xlabel(f'RDA1 ({constrained_var[0]:.1f}%)')\nplt.ylabel(f'RDA2 ({constrained_var[1]:.1f}%)')\nplt.show()\n\nprint(\"\\nâœ¨ RDA plotting now works just like R nuee:\")\nprint(\"   rda_result.plot()     # Site scores\")\nprint(\"   rda_result.biplot()   # Biplot with environmental arrows\")\nprint(\"   rda_result.plot(display='species')  # Species scores\")\n\ntotal_constrained = np.sum(constrained_var)\nprint(f\"\\nRDA Interpretation:\")\nprint(f\"  â€¢ Environmental variables explain {total_constrained:.1f}% of community variation\")\nprint(f\"  â€¢ RDA1 and RDA2 together explain {np.sum(constrained_var[:2]):.1f}% of total variation\")\nprint(f\"  â€¢ Red arrows show environmental gradients in community space\")\nprint(f\"  â€¢ Sites positioned along arrows have high values of those variables\")"
  },
  {
   "cell_type": "markdown",
   "id": "significance",
   "metadata": {},
   "source": [
    "### 4.1 Significance Tests {#significance}\n",
    "\n",
    "Permutation tests help determine if the environmental variables significantly explain community patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significance_tests",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Significance testing for RDA\n",
    "print(\"=== SIGNIFICANCE TESTS FOR CONSTRAINED ORDINATION ===\")\n",
    "\n",
    "try:\n",
    "    # Test overall significance of the RDA model\n",
    "    # This would typically be done with anova.cca() in nuee\n",
    "    print(\"Overall RDA model test:\")\n",
    "    print(f\"  Pseudo-F ratio: [under development]\")\n",
    "    print(f\"  P-value: [under development]\")\n",
    "    \n",
    "    # Test significance of individual axes\n",
    "    print(\"\\nIndividual axis tests:\")\n",
    "    for i, eig in enumerate(rda_result.constrained_eig[:3]):\n",
    "        print(f\"  RDA{i+1}: eigenvalue = {eig:.4f} [p-value under development]\")\n",
    "    \n",
    "    # Test significance of individual environmental variables\n",
    "    print(\"\\nIndividual variable tests (marginal effects):\")\n",
    "    for var in varechem.columns:\n",
    "        print(f\"  {var}: [F-ratio and p-value under development]\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Significance testing: {e}\")\n",
    "    print(\"Note: Permutation tests are under development\")\n",
    "\n",
    "# Manual F-ratio calculation for the overall model\n",
    "print(\"\\nManual model evaluation:\")\n",
    "if rda_result.constrained_eig is not None and rda_result.unconstrained_eig is not None:\n",
    "    # Calculate pseudo F-ratio\n",
    "    n_sites = varespec.shape[0]\n",
    "    n_env_vars = varechem.shape[1]\n",
    "    \n",
    "    constrained_variance = np.sum(rda_result.constrained_eig)\n",
    "    unconstrained_variance = np.sum(rda_result.unconstrained_eig)\n",
    "    \n",
    "    # Degrees of freedom\n",
    "    df_constrained = n_env_vars\n",
    "    df_residual = n_sites - n_env_vars - 1\n",
    "    \n",
    "    # Pseudo F-ratio\n",
    "    f_ratio = (constrained_variance / df_constrained) / (unconstrained_variance / df_residual)\n",
    "    \n",
    "    print(f\"  Constrained variance: {constrained_variance:.4f}\")\n",
    "    print(f\"  Residual variance: {unconstrained_variance:.4f}\")\n",
    "    print(f\"  Pseudo F-ratio: {f_ratio:.4f}\")\n",
    "    print(f\"  Degrees of freedom: {df_constrained}, {df_residual}\")\n",
    "    \n",
    "    # Rough interpretation (without permutation p-value)\n",
    "    if f_ratio > 2:\n",
    "        print(f\"  Interpretation: Likely significant effect (F > 2)\")\n",
    "    else:\n",
    "        print(f\"  Interpretation: Weak or non-significant effect (F < 2)\")\n",
    "\n",
    "print(\"\\nNote: In practice, p-values should be calculated using permutation tests\")\n",
    "print(\"This ensures proper statistical inference for ecological data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "partial",
   "metadata": {},
   "source": [
    "### 4.2 Conditioned or Partial Ordination {#partial}\n",
    "\n",
    "Partial ordination allows us to control for certain variables while examining the effects of others. This is useful for controlling for spatial or temporal effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial_ordination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partial/Conditioned ordination\n",
    "print(\"=== PARTIAL (CONDITIONED) ORDINATION ===\")\n",
    "\n",
    "# Example: Partial out the effect of pH and examine other variables\n",
    "# We'll condition on pH and N, then look at the effect of other variables\n",
    "\n",
    "try:\n",
    "    # Conditioning variables (variables to partial out)\n",
    "    conditioning_vars = varechem[['pH', 'N']]\n",
    "    \n",
    "    # Variables of interest (remaining environmental variables)\n",
    "    remaining_vars = varechem.drop(['pH', 'N'], axis=1)\n",
    "    \n",
    "    print(f\"Conditioning on: {list(conditioning_vars.columns)}\")\n",
    "    print(f\"Testing effect of: {list(remaining_vars.columns)}\")\n",
    "    \n",
    "    # Partial RDA\n",
    "    partial_rda = nuee.rda(varespec, remaining_vars, conditioning_vars)\n",
    "    \n",
    "    print(f\"\\nPartial RDA Results:\")\n",
    "    print(f\"  Total inertia: {partial_rda.tot_chi:.4f}\")\n",
    "    \n",
    "    if hasattr(partial_rda, 'partial_chi') and partial_rda.partial_chi is not None:\n",
    "        print(f\"  Conditioned (partial) inertia: {partial_rda.partial_chi:.4f}\")\n",
    "        conditioned_percent = partial_rda.partial_chi / partial_rda.tot_chi * 100\n",
    "        print(f\"  Variance explained by conditioning vars: {conditioned_percent:.1f}%\")\n",
    "    \n",
    "    if partial_rda.constrained_eig is not None:\n",
    "        constrained_inertia = np.sum(partial_rda.constrained_eig)\n",
    "        constrained_percent = constrained_inertia / partial_rda.tot_chi * 100\n",
    "        print(f\"  Constrained inertia (after conditioning): {constrained_inertia:.4f}\")\n",
    "        print(f\"  Variance explained by remaining vars: {constrained_percent:.1f}%\")\n",
    "    \n",
    "    if partial_rda.unconstrained_eig is not None and len(partial_rda.unconstrained_eig) > 0:\n",
    "        residual_inertia = np.sum(partial_rda.unconstrained_eig)\n",
    "        residual_percent = residual_inertia / partial_rda.tot_chi * 100\n",
    "        print(f\"  Residual inertia: {residual_inertia:.4f}\")\n",
    "        print(f\"  Unexplained variance: {residual_percent:.1f}%\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Partial RDA: {e}\")\n",
    "    print(\"Partial ordination implementation is under development\")\n",
    "    \n",
    "    # Alternative: Sequential analysis\n",
    "    print(\"\\nAlternative approach: Sequential model comparison\")\n",
    "    \n",
    "    # Model 1: Only conditioning variables\n",
    "    rda_cond = nuee.rda(varespec, conditioning_vars)\n",
    "    cond_variance = np.sum(rda_cond.constrained_eig) if rda_cond.constrained_eig is not None else 0\n",
    "    \n",
    "    # Model 2: All variables\n",
    "    rda_full = nuee.rda(varespec, varechem)\n",
    "    full_variance = np.sum(rda_full.constrained_eig) if rda_full.constrained_eig is not None else 0\n",
    "    \n",
    "    # Pure effect of remaining variables\n",
    "    pure_effect = full_variance - cond_variance\n",
    "    pure_percent = pure_effect / rda_full.tot_chi * 100\n",
    "    \n",
    "    print(f\"  Conditioning variables explain: {cond_variance/rda_full.tot_chi*100:.1f}%\")\n",
    "    print(f\"  All variables explain: {full_variance/rda_full.tot_chi*100:.1f}%\")\n",
    "    print(f\"  Pure effect of remaining variables: {pure_percent:.1f}%\")\n",
    "\n",
    "print(\"\\nPartial ordination is useful for:\")\n",
    "print(\"  â€¢ Controlling for spatial autocorrelation\")\n",
    "print(\"  â€¢ Removing the effect of known confounding variables\")\n",
    "print(\"  â€¢ Testing pure effects of variable groups\")\n",
    "print(\"  â€¢ Variance partitioning studies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variance_partitioning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance partitioning example\n",
    "print(\"=== VARIANCE PARTITIONING EXAMPLE ===\")\n",
    "\n",
    "# Partition variance between two groups of environmental variables\n",
    "# Group 1: Chemical variables (pH, N, P, K)\n",
    "# Group 2: Other variables (Ca, Mg)\n",
    "\n",
    "chem_vars = varechem[['pH', 'N', 'P', 'K']]\n",
    "other_vars = varechem[['Ca', 'Mg']]\n",
    "\n",
    "print(f\"Group 1 (Chemical): {list(chem_vars.columns)}\")\n",
    "print(f\"Group 2 (Other): {list(other_vars.columns)}\")\n",
    "\n",
    "# RDA with chemical variables only\n",
    "rda_chem = nuee.rda(varespec, chem_vars)\n",
    "var_chem = np.sum(rda_chem.constrained_eig) if rda_chem.constrained_eig is not None else 0\n",
    "\n",
    "# RDA with other variables only  \n",
    "rda_other = nuee.rda(varespec, other_vars)\n",
    "var_other = np.sum(rda_other.constrained_eig) if rda_other.constrained_eig is not None else 0\n",
    "\n",
    "# RDA with all variables\n",
    "rda_all = nuee.rda(varespec, varechem)\n",
    "var_all = np.sum(rda_all.constrained_eig) if rda_all.constrained_eig is not None else 0\n",
    "\n",
    "# Calculate variance components\n",
    "total_inertia = rda_all.tot_chi\n",
    "\n",
    "# [a] Pure effect of chemical variables = var_all - var_other\n",
    "pure_chem = var_all - var_other\n",
    "\n",
    "# [b] Pure effect of other variables = var_all - var_chem  \n",
    "pure_other = var_all - var_chem\n",
    "\n",
    "# [c] Shared effect = var_chem + var_other - var_all\n",
    "shared = var_chem + var_other - var_all\n",
    "\n",
    "# [d] Residual = total_inertia - var_all\n",
    "residual = total_inertia - var_all\n",
    "\n",
    "print(f\"\\nVariance Partitioning Results:\")\n",
    "print(f\"  [a] Pure Chemical effect: {pure_chem:.4f} ({pure_chem/total_inertia*100:.1f}%)\")\n",
    "print(f\"  [b] Pure Other effect: {pure_other:.4f} ({pure_other/total_inertia*100:.1f}%)\")\n",
    "print(f\"  [c] Shared effect: {shared:.4f} ({shared/total_inertia*100:.1f}%)\")\n",
    "print(f\"  [d] Residual: {residual:.4f} ({residual/total_inertia*100:.1f}%)\")\n",
    "print(f\"  Total: {total_inertia:.4f} (100.0%)\")\n",
    "\n",
    "# Visualize variance partitioning\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Pie chart\n",
    "components = [pure_chem, pure_other, shared, residual]\n",
    "labels = ['Pure Chemical', 'Pure Other', 'Shared', 'Residual']\n",
    "colors = ['lightblue', 'lightcoral', 'lightgreen', 'lightgray']\n",
    "\n",
    "# Only plot positive components\n",
    "pos_components = [max(0, comp) for comp in components]\n",
    "percentages = [comp/total_inertia*100 for comp in pos_components]\n",
    "\n",
    "wedges, texts, autotexts = ax1.pie(pos_components, labels=labels, colors=colors, \n",
    "                                  autopct='%1.1f%%', startangle=90)\n",
    "ax1.set_title('Variance Partitioning')\n",
    "\n",
    "# Bar chart\n",
    "ax2.bar(labels, percentages, color=colors, alpha=0.7, edgecolor='black')\n",
    "ax2.set_ylabel('Percentage of Total Variance')\n",
    "ax2.set_title('Variance Components')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "if pure_chem > pure_other:\n",
    "    print(f\"  â€¢ Chemical variables have stronger pure effect than other variables\")\n",
    "else:\n",
    "    print(f\"  â€¢ Other variables have stronger pure effect than chemical variables\")\n",
    "\n",
    "if shared > 0:\n",
    "    print(f\"  â€¢ Positive shared effect suggests variables are correlated\")\n",
    "else:\n",
    "    print(f\"  â€¢ Negative shared effect suggests suppression or confounding\")\n",
    "\n",
    "explained_total = (pure_chem + pure_other + shared) / total_inertia * 100\n",
    "print(f\"  â€¢ Total explained variance: {explained_total:.1f}%\")\n",
    "print(f\"  â€¢ Environmental variables explain a {'substantial' if explained_total > 50 else 'moderate' if explained_total > 20 else 'small'} portion of community variation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## Summary and Conclusions\n",
    "\n",
    "This tutorial has demonstrated the main ordination techniques available in nuee, following the structure of the classic nuee introduction. We covered:\n",
    "\n",
    "### Key Techniques Demonstrated:\n",
    "\n",
    "1. **Unconstrained Ordination**\n",
    "   - NMDS for robust community analysis\n",
    "   - Stress interpretation and quality assessment\n",
    "\n",
    "2. **Ordination Graphics**\n",
    "   - Strategies for handling cluttered plots\n",
    "   - Adding environmental information and group structure\n",
    "   - Creating publication-ready figures\n",
    "\n",
    "3. **Environmental Fitting**\n",
    "   - Correlating environmental variables with ordination patterns\n",
    "   - Visualizing environmental gradients as vectors\n",
    "   - Interpreting goodness-of-fit measures\n",
    "\n",
    "4. **Constrained Ordination**\n",
    "   - RDA for linear relationships\n",
    "   - Variance partitioning between variable groups\n",
    "   - Understanding constrained vs. residual variation\n",
    "\n",
    "5. **Statistical Testing** (framework established)\n",
    "   - Significance testing approaches\n",
    "   - Partial ordination concepts\n",
    "   - Model comparison strategies\n",
    "\n",
    "### Ecological Insights:\n",
    "\n",
    "- Environmental variables explain a meaningful portion of lichen community variation\n",
    "- Chemical gradients (pH, nutrients) are important drivers of community structure\n",
    "- Both pure and shared effects of environmental variables contribute to community patterns\n",
    "- NMDS provides a robust visualization of community relationships\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Apply these methods to your own ecological datasets\n",
    "- Explore additional ordination methods (CCA for unimodal responses)\n",
    "- Investigate temporal and spatial patterns in community data\n",
    "- Combine ordination with other multivariate techniques\n",
    "- Consider functional diversity and phylogenetic approaches\n",
    "\n",
    "nuee provides a comprehensive toolkit for ecological ordination analysis in Python, maintaining the philosophical approach of the original nuee package while leveraging Python's scientific computing ecosystem."
   ]
  },
  {
   "cell_type": "code",
   "id": "y6wpcrfj64h",
   "source": "# nuee vs R nuee: Automatic Plotting Comparison\nprint(\"ðŸ”„ nuee vs R nuee: AUTOMATIC PLOTTING COMPARISON\")\nprint(\"=\" * 60)\n\nprint(\"\\nR nuee workflow:\")\nprint(\"  library(nuee)\")\nprint(\"  data(varespec)\")\nprint(\"  data(varechem)\")\nprint(\"  \")\nprint(\"  # Diversity analysis\")\nprint(\"  shannon_div <- diversity(varespec, index='shannon')\")\nprint(\"  plot(shannon_div)  # Automatic plotting\")\nprint(\"  \")\nprint(\"  # Ordination analysis\")\nprint(\"  nmds_result <- metaMDS(varespec)\")\nprint(\"  plot(nmds_result)  # Automatic plotting\")\nprint(\"  \")\nprint(\"  # Constrained ordination\")\nprint(\"  rda_result <- rda(varespec ~ N + P + K, data=varechem)\")\nprint(\"  plot(rda_result)   # Automatic plotting\")\n\nprint(\"\\nnuee workflow (now with automatic plotting!):\")\nprint(\"  import nuee \")\nprint(\"  species = nuee.datasets.varespec()\")\nprint(\"  environment = nuee.datasets.varechem()\")\nprint(\"  \")\nprint(\"  # Diversity analysis\")\nprint(\"  shannon_div = nuee.shannon(species)\")\nprint(\"  shannon_div.plot()  # Automatic plotting!\")\nprint(\"  \")\nprint(\"  # Ordination analysis\")\nprint(\"  nmds_result = nuee.metaMDS(species)\")\nprint(\"  nmds_result.plot()  # Automatic plotting!\")\nprint(\"  \")\nprint(\"  # Constrained ordination\")\nprint(\"  rda_result = nuee.rda(species, environment[['N', 'P', 'K']])\")\nprint(\"  rda_result.biplot()  # Automatic plotting!\")\n\nprint(\"\\nâœ¨ Live demonstration of automatic plotting:\")\n\n# Shannon diversity\nshannon_demo = nuee.shannon(varespec)\nprint(f\"\\n1. Shannon diversity: {type(shannon_demo)}\")\nprint(f\"   Has plot method: {hasattr(shannon_demo, 'plot')}\")\nfig1 = shannon_demo.plot(kind=\"box\", figsize=(8, 5))\nplt.title(\"Shannon Diversity - Automatic Plotting Demo\")\nplt.show()\n\n# NMDS\nnmds_demo = nuee.metaMDS(varespec, k=2, trace=False)\nprint(f\"\\n2. NMDS result: {type(nmds_demo)}\")\nprint(f\"   Has plot method: {hasattr(nmds_demo, 'plot')}\")\nfig2 = nmds_demo.plot(display=\"sites\", figsize=(8, 5))\nplt.title(\"NMDS Sites - Automatic Plotting Demo\")\nplt.show()\n\n# RDA\nrda_demo = nuee.rda(varespec, varechem[['N', 'P', 'K']])\nprint(f\"\\n3. RDA result: {type(rda_demo)}\")\nprint(f\"   Has biplot method: {hasattr(rda_demo, 'biplot')}\")\nfig3 = rda_demo.biplot(figsize=(8, 5))\nplt.title(\"RDA Biplot - Automatic Plotting Demo\")\nplt.show()\n\nprint(\"\\nðŸŽ‰ SUCCESS! nuee now works just like R nuee!\")\nprint(\"ðŸ“Š All analysis results can be plotted directly\")\nprint(\"ðŸ”„ Syntax is now very similar to R nuee\")\nprint(\"âœ¨ No need for separate plotting functions\")",
   "metadata": {},
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}